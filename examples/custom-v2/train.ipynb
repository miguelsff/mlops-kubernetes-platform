{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb6d9e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import mlflow.pyfunc\n",
    "from mlflow.models.signature import infer_signature\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class CustomModel:\n",
    "    def remove_accents(self, col_name):\n",
    "        accent_mapping = {\n",
    "            r\"Á\": \"A\", r\"É\": \"E\", r\"Í\": \"I\", r\"Ó\": \"O\", r\"Ú\": \"U\",\n",
    "            r\"Â\": \"A\", r\"Ê\": \"E\", r\"Î\": \"I\", r\"Ô\": \"O\", r\"Û\": \"U\",\n",
    "            r\"Ä\": \"A\", r\"Ë\": \"E\", r\"Ï\": \"I\", r\"Ö\": \"O\", r\"Ü\": \"U\",\n",
    "            r\"À\": \"A\", r\"È\": \"E\", r\"Ì\": \"I\", r\"Ò\": \"O\", r\"Ù\": \"U\",\n",
    "            r\"Ñ\": \"N\", r\"Ý\": \"Y\", r\"Ç\": \"C\", r\"Ã\": \"A\", r\"Õ\": \"O\"\n",
    "            # ,\".\":\"\"             # Added period replacement with nothing\n",
    "            }\n",
    "        for character, replacement in accent_mapping.items():\n",
    "            col_name = re.sub(character, replacement, col_name)\n",
    "        return col_name\n",
    "\n",
    "    def remove_special_chars(self, col_name):\n",
    "        return re.sub(r'[^a-zA-Z0-9\\s]', '', col_name)\n",
    "\n",
    "    def remove_spaces(self, col_name):\n",
    "        return re.sub(r' ', '', col_name)\n",
    "\n",
    "    def preprocess_transactions(self, transactions):\n",
    "        try:\n",
    "            transactions['description'] = transactions['description'].str.upper()\n",
    "            transactions['description'] = transactions['description'].apply(self.remove_accents)\n",
    "            transactions['description'] = transactions['description'].apply(self.remove_special_chars)\n",
    "            transactions['description'] = transactions['description'].apply(self.remove_spaces)\n",
    "            transactions = transactions.drop_duplicates()\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        return transactions\n",
    "\n",
    "    def predict(self, transactions, percentiles):\n",
    "        try:\n",
    "            transactions = self.preprocess_transactions(transactions)\n",
    "            merged = pd.merge(transactions, percentiles, on=[\"description\"], how=\"left\")\n",
    "            merged[\"flag_p25\"] = (merged[\"price\"] < merged[\"p25\"]).astype(int)\n",
    "            merged = merged.reset_index(drop=True)\n",
    "            merged['amount_difference'] = merged['p25'] - merged['price']\n",
    "            merged['differential_tax'] = merged['amount_difference'] * merged['quantity'] * 0.18\n",
    "            merged = merged.reset_index(drop=True)\n",
    "            merged['ratio'] = merged['differential_tax'] / 700\n",
    "            merged['ratio'] = merged['ratio'].mask(merged['ratio'] > 1, 1)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        return np.array(merged[['ratio']])\n",
    "\n",
    "\n",
    "class CustomModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def load_context(self, context):\n",
    "        # Load percentiles CSV from artifacts\n",
    "        self.percentiles_df = pd.read_csv(context.artifacts[\"percentiles\"])\n",
    "\n",
    "    def predict(self, context, transactions):\n",
    "        return self.model.predict(transactions, self.percentiles_df)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('train.log'),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "PERCENTILES_PATH = 'data/raw/percentiles.csv'\n",
    "TRANSACTIONS_PATH = 'data/raw/transactions.csv'\n",
    "\n",
    "\n",
    "def load_percentiles():\n",
    "    percentiles = pd.read_csv(\n",
    "        PERCENTILES_PATH,\n",
    "        sep=',',\n",
    "        encoding='utf_8',\n",
    "        dtype={\n",
    "            'code': str,\n",
    "            'description': str,\n",
    "            'p25': float,\n",
    "            'p50': float,\n",
    "            'p75': float\n",
    "            }\n",
    "    )\n",
    "    return percentiles\n",
    "\n",
    "\n",
    "def load_transactions():\n",
    "    transactions = pd.read_csv(\n",
    "        TRANSACTIONS_PATH,\n",
    "        sep=',',\n",
    "        encoding='utf_8',\n",
    "        dtype={\n",
    "            'description': str,\n",
    "            'quantity': float,\n",
    "            'price': float\n",
    "            }\n",
    "    )\n",
    "    return transactions\n",
    "\n",
    "\n",
    "def load_inference_example_data():\n",
    "    try:\n",
    "        dataset = load_transactions()\n",
    "        logger.info(\n",
    "            f\"Inference example data loaded successfully. Shape: {dataset.shape}\")\n",
    "        return dataset.head(1).to_dict('records')[0]\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading inference example data: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "example = load_inference_example_data()\n",
    "\n",
    "\n",
    "# Pydantic class for schema definition\n",
    "class TransactionInput(BaseModel):\n",
    "    description: str = example['description']\n",
    "    quantity: float = example['quantity']\n",
    "    price: float = example['price']\n",
    "\n",
    "\n",
    "# Create input_example\n",
    "input_example = pd.DataFrame([TransactionInput().model_dump()])\n",
    "\n",
    "# Export schema.json\n",
    "schema = TransactionInput.model_json_schema()\n",
    "with open(\"TransactionInput.json\", \"w\") as f:\n",
    "    json.dump(schema, f, indent=2)\n",
    "\n",
    "# Train model and log everything\n",
    "mlflow.set_tracking_uri(\"http://20.120.201.119:5000\")\n",
    "mlflow.set_experiment(\"minimal_model_experiment\")\n",
    "\n",
    "percentiles = load_percentiles()\n",
    "transactions = load_transactions()\n",
    "\n",
    "os.makedirs(\"model_artifacts\", exist_ok=True)\n",
    "percentiles.to_csv(\"model_artifacts/percentiles.csv\", index=False)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    customModel = CustomModel()\n",
    "    output = customModel.predict(transactions, percentiles)\n",
    "\n",
    "    signature = infer_signature(transactions, output)\n",
    "\n",
    "    # Register model with input_example and signature\n",
    "    mlflow.pyfunc.log_model(\n",
    "        python_model=CustomModelWrapper(customModel),\n",
    "        artifact_path=\"model\",\n",
    "        artifacts={\"percentiles\": \"model_artifacts/percentiles.csv\"},\n",
    "        input_example=input_example,\n",
    "        signature=signature\n",
    "    )\n",
    "\n",
    "    # Attach schema.json as additional artifact\n",
    "    mlflow.log_artifact(\"TransactionInput.json\", artifact_path=\"schemas\")\n",
    "\n",
    "    print(\n",
    "        \"✅ Model trained, input_example validated and schema.json registered.\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
