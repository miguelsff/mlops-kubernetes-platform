{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec20f01",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import ray\n",
    "import pandas as pd\n",
    "import mlflow.pyfunc\n",
    "from fastapi import FastAPI, Request\n",
    "from json.decoder import JSONDecodeError\n",
    "from jsonschema import validate, ValidationError\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.exceptions import MlflowException\n",
    "from ray import serve\n",
    "from typing import Any, Dict\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('import_model.log'),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Connect to Ray cluster\n",
    "if not ray.is_initialized():\n",
    "    ray.init(address=\"ray://raycluster-kuberay-head-svc:10001\")\n",
    "\n",
    "# Initialize Ray Serve\n",
    "serve.start(detached=True, http_options={\"host\": \"0.0.0.0\", \"port\": 8000})\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    'NAME': \"minimal_model\",\n",
    "    'VERSION': \"5\",\n",
    "    'INPUT_SCHEMA': \"TransactionInput.json\",\n",
    "    'ROUTE_PREFIX': \"/v1\"\n",
    "}\n",
    "\n",
    "MLFLOW_IP = \"20.120.201.119\"\n",
    "RAY_IP = \"20.29.159.59\"\n",
    "\n",
    "# FastAPI application\n",
    "app = FastAPI(\n",
    "    title=\"Minimal Predictor API\",\n",
    "    description=\"Import Pipeline online inference\"\n",
    ")\n",
    "\n",
    "\n",
    "@serve.deployment(ray_actor_options={\"num_cpus\": 0.1})\n",
    "@serve.ingress(app)\n",
    "class MinimalModel:\n",
    "    def __init__(self):\n",
    "        self.model = self._load_model(\n",
    "            f\"models:/{MODEL_CONFIG['NAME']}/{MODEL_CONFIG['VERSION']}\")\n",
    "        self.schema = self._load_schema(self.model.metadata.run_id)\n",
    "        self.columns = list(self.schema[\"properties\"].keys())\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_model(model_uri: str):\n",
    "        mlflow.set_tracking_uri(f\"http://{MLFLOW_IP}:5000\")\n",
    "        return mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_schema(run_id: str) -> Dict[str, Any]:\n",
    "        client = MlflowClient()\n",
    "        schema_dir = client.download_artifacts(run_id, \"schemas\")\n",
    "        with open(os.path.join(schema_dir, MODEL_CONFIG['INPUT_SCHEMA'])) as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    @staticmethod\n",
    "    async def _parse_request(request: Request) -> Dict[str, Any]:\n",
    "        try:\n",
    "            return await request.json()\n",
    "        except JSONDecodeError as e:\n",
    "            raise ValueError(f\"❌ Invalid JSON: {e.msg} at position {e.pos}\")\n",
    "\n",
    "    def _validate_input(self, data: Dict[str, Any]) -> None:\n",
    "        try:\n",
    "            validate(instance=data, schema=self.schema)\n",
    "        except ValidationError as e:\n",
    "            raise ValueError(f\"❌ JSON Schema validation error: {e.message}\")\n",
    "\n",
    "    def _to_dataframe(self, data: Dict[str, Any]) -> pd.DataFrame:\n",
    "        try:\n",
    "            values = [\n",
    "                float(data[col])\n",
    "                if self.schema[\"properties\"][col].get(\"type\") == \"number\"\n",
    "                else data[col]\n",
    "                for col in self.columns\n",
    "            ]\n",
    "            return pd.DataFrame([values], columns=self.columns)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"❌ Error converting data to DataFrame: {e}\")\n",
    "\n",
    "    @app.post(\"/\")\n",
    "    async def predict(self, request: Request):\n",
    "        try:\n",
    "            data = await self._parse_request(request)\n",
    "            self._validate_input(data)\n",
    "            row = self._to_dataframe(data)\n",
    "            pred = self.model.predict(row)\n",
    "            logger.info(f\"Inference prediction: {pred}\")\n",
    "            if np.isnan(pred).any():\n",
    "                logger.warning(\"⚠️ Prediction contains NaN values, replacing with 0.0\")\n",
    "                pred = np.nan_to_num(pred, nan=0.0)\n",
    "            return {\n",
    "                \"code\": 200,\n",
    "                \"message\": \"Score calculated successfully.\",\n",
    "                \"data\": {\"import_event_probability\": pred.tolist()},\n",
    "                \"errors\": None\n",
    "            }\n",
    "        except ValueError as ve:\n",
    "            return {\"error\": str(ve)}\n",
    "        except MlflowException as me:\n",
    "            return {\n",
    "                \"error\": \"❌ Prediction error\",\n",
    "                \"message\": str(me).split(\"Error:\")[-1].strip()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"❌ Unexpected error: {str(e)}\"}\n",
    "\n",
    "\n",
    "# Deploy model\n",
    "serve.run(MinimalModel.bind(),\n",
    "          name=f\"{MODEL_CONFIG['NAME']}_app\",\n",
    "          route_prefix=MODEL_CONFIG['ROUTE_PREFIX'])\n",
    "\n",
    "print(f\"✅ Model deployed at http://{RAY_IP}:8000{MODEL_CONFIG['ROUTE_PREFIX']}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
